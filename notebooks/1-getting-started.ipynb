{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf82784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T10:40:36.902544Z",
     "iopub.status.busy": "2025-12-16T10:40:36.901653Z",
     "iopub.status.idle": "2025-12-16T10:40:52.718280Z",
     "shell.execute_reply": "2025-12-16T10:40:52.716982Z"
    },
    "papermill": {
     "duration": 15.823603,
     "end_time": "2025-12-16T10:40:52.720018",
     "exception": false,
     "start_time": "2025-12-16T10:40:36.896415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%uv pip install numerapi pyarrow numerai-tools -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfb0ab",
   "metadata": {
    "papermill": {
     "duration": 0.003777,
     "end_time": "2025-12-16T10:40:52.728373",
     "exception": false,
     "start_time": "2025-12-16T10:40:52.724596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset  \n",
    "\n",
    "At a high level, the Numerai dataset is a tabular dataset that describes the stock market over time. It is compiled from high-quality (and expensive) data that might be difficult for individuals to obtain.\n",
    "\n",
    "The unique thing about Numerai's dataset is that it is `obfuscated`, which means that the underlying stock ids, feature names, and target definitions are anonymized. This makes it so that Numerai can give this data out for free and so that it can be modeled without any financial domain knowledge (or bias!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba73944",
   "metadata": {
    "papermill": {
     "duration": 0.003549,
     "end_time": "2025-12-16T10:40:52.735649",
     "exception": false,
     "start_time": "2025-12-16T10:40:52.732100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Listing the datasets\n",
    "Firstly, take a look at the files Numerai offers below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed89d19a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T10:40:52.744578Z",
     "iopub.status.busy": "2025-12-16T10:40:52.744199Z",
     "iopub.status.idle": "2025-12-16T10:40:55.304431Z",
     "shell.execute_reply": "2025-12-16T10:40:55.303282Z"
    },
    "papermill": {
     "duration": 2.566677,
     "end_time": "2025-12-16T10:40:55.305861",
     "exception": false,
     "start_time": "2025-12-16T10:40:52.739184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available versions:\n",
      " ['v5.1', 'v5.0', 'v5.2']\n",
      "Available v5.1 files:\n",
      " ['v5.1/features.json', 'v5.1/live.parquet', 'v5.1/live_benchmark_models.parquet', 'v5.1/live_example_preds.csv', 'v5.1/live_example_preds.parquet', 'v5.1/meta_model.parquet', 'v5.1/train.parquet', 'v5.1/train_benchmark_models.parquet', 'v5.1/validation.parquet', 'v5.1/validation_benchmark_models.parquet', 'v5.1/validation_example_preds.csv', 'v5.1/validation_example_preds.parquet']\n"
     ]
    }
   ],
   "source": [
    "# Initialize NumerAPI - the official Python API client for Numerai\n",
    "from numerapi import NumerAPI\n",
    "napi = NumerAPI()\n",
    "\n",
    "# list the datasets and available versions\n",
    "all_datasets = napi.list_datasets()\n",
    "dataset_versions = list(set(d.split('/')[0] for d in all_datasets))\n",
    "print(\"Available versions:\\n\", dataset_versions)\n",
    "\n",
    "# Set data version to one of the latest datasets\n",
    "DATA_VERSION = \"v5.1\"\n",
    "\n",
    "# Print all files available for download for our version\n",
    "current_version_files = [f for f in all_datasets if f.startswith(DATA_VERSION)]\n",
    "print(\"Available\", DATA_VERSION, \"files:\\n\", current_version_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a94d8",
   "metadata": {
    "papermill": {
     "duration": 0.003648,
     "end_time": "2025-12-16T10:40:55.313397",
     "exception": false,
     "start_time": "2025-12-16T10:40:55.309749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Downloading datasets\n",
    "\n",
    "The `features.json` file contains metadata about features in the dataset including:\n",
    "- statistics on each feature\n",
    "- helpful sets of features\n",
    "- the targets available for training\n",
    "\n",
    "Let's download it and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cc9718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T10:40:55.322354Z",
     "iopub.status.busy": "2025-12-16T10:40:55.321661Z",
     "iopub.status.idle": "2025-12-16T10:40:56.203905Z",
     "shell.execute_reply": "2025-12-16T10:40:56.202770Z"
    },
    "papermill": {
     "duration": 0.888768,
     "end_time": "2025-12-16T10:40:56.205545",
     "exception": false,
     "start_time": "2025-12-16T10:40:55.316777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 10:40:55,984 INFO numerapi.utils: starting download\n",
      "v5.1/features.json: 307kB [00:00, 1.58MB/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_sets 18\n",
      "targets 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# download the feature metadata file\n",
    "napi.download_dataset(f\"{DATA_VERSION}/features.json\")\n",
    "\n",
    "# read the metadata and display\n",
    "feature_metadata = json.load(open(f\"{DATA_VERSION}/features.json\"))\n",
    "for metadata in feature_metadata:\n",
    "  print(metadata, len(feature_metadata[metadata]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017d16a",
   "metadata": {
    "papermill": {
     "duration": 0.004008,
     "end_time": "2025-12-16T10:40:56.213873",
     "exception": false,
     "start_time": "2025-12-16T10:40:56.209865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Sets & Groups\n",
    "As you can see there are many features and targets to choose from.\n",
    "\n",
    "Instead of training a model on all 2000+ features, let's pick a subset of features to analyze.\n",
    "\n",
    "Here are a few starter sets Numerai offers:\n",
    "\n",
    "- `small` contains a minimal subset of features that have the highest [feature importance](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n",
    "\n",
    "- `medium` contains all the \"basic\" features, each unique in some way (e.g. P/E ratios vs analyst ratings)\n",
    "\n",
    "- `all` contains all features in `medium` and their variants (e.g. P/E by country vs P/E by sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09472c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T10:40:56.225142Z",
     "iopub.status.busy": "2025-12-16T10:40:56.224100Z",
     "iopub.status.idle": "2025-12-16T10:40:56.230140Z",
     "shell.execute_reply": "2025-12-16T10:40:56.229124Z"
    },
    "papermill": {
     "duration": 0.013181,
     "end_time": "2025-12-16T10:40:56.231611",
     "exception": false,
     "start_time": "2025-12-16T10:40:56.218430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small 42\n",
      "medium 740\n",
      "all 2562\n"
     ]
    }
   ],
   "source": [
    "feature_sets = feature_metadata[\"feature_sets\"]\n",
    "for feature_set in [\"small\", \"medium\", \"all\"]:\n",
    "  print(feature_set, len(feature_sets[feature_set]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4509b4",
   "metadata": {
    "papermill": {
     "duration": 0.004052,
     "end_time": "2025-12-16T10:40:56.240142",
     "exception": false,
     "start_time": "2025-12-16T10:40:56.236090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's load the data. Here we pick the smallest feature set for performance optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460043f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T10:40:56.250989Z",
     "iopub.status.busy": "2025-12-16T10:40:56.250166Z",
     "iopub.status.idle": "2025-12-16T10:44:23.864463Z",
     "shell.execute_reply": "2025-12-16T10:44:23.863087Z"
    },
    "papermill": {
     "duration": 207.621489,
     "end_time": "2025-12-16T10:44:23.865804",
     "exception": true,
     "start_time": "2025-12-16T10:40:56.244315",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define our feature set\n",
    "feature_set = feature_sets[\"small\"]\n",
    "\n",
    "# Download the training data - this will take a few minutes\n",
    "napi.download_dataset(f\"{DATA_VERSION}/train.parquet\")\n",
    "train = pd.read_parquet(\n",
    "    f\"{DATA_VERSION}/train.parquet\",\n",
    "    columns=[\"era\", \"target\"] + feature_set\n",
    ")\n",
    "\n",
    "# Download validation data - this will take a few minutes\n",
    "napi.download_dataset(f\"{DATA_VERSION}/validation.parquet\")\n",
    "validation = pd.read_parquet(\n",
    "    f\"{DATA_VERSION}/validation.parquet\",\n",
    "    columns=[\"era\", \"target\"] + feature_set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b3a47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Training data\n",
    "\n",
    "Each row represents a stock at a specific point in time:\n",
    "- `id` is the stock id\n",
    "- `era` is the date\n",
    "- `target` is a measure of future returns for that stock\n",
    "- `features` describe the attributes of the stock (eg. P/E ratio) for that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc908b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b4e93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Eras\n",
    "As mentioned above, each `era` corresponds to a different date. Each era is exactly 1 week apart.\n",
    "\n",
    "It is helpful to think about rows of stocks within the same `era` as a single example. You will notice that throughout this notebook and other examples, we often talk about things \"per era\". For example, the number of rows per era represents the number of stocks in Numerai's investable universe on that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee992b85",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the number of rows per era\n",
    "train.groupby(\"era\").size().plot(\n",
    "    title=\"Number of rows per era\",\n",
    "    figsize=(5, 3),\n",
    "    xlabel=\"Era\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ed22b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_eras = train[\"era\"].unique()\n",
    "print(f'There are {len(train_eras)} eras in the training set going from {train_eras[0]} to {train_eras[-1]}')\n",
    "\n",
    "validation_eras = validation[\"era\"].unique()\n",
    "print(f'There are {len(validation_eras)} eras in the validation set going from {validation_eras[0]} to {validation_eras[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ac867",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We're gonna keep the last 100 eras for the test set and only look at them to have our final model performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85705d58",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Target\n",
    "The `target` is a measure of stock market returns over the next 20 (business) days. Specifically, it is a measure of \"stock-specific\" returns that are not explained by well-known \"factors\" or broader trends in the market, country, or sector. For example, if Apple went up and the tech sector also went up, we only want to know if Apple went up more or less than the tech sector. This means the target focus on `alpha`, not on `beta`\n",
    "\n",
    "Target values are binned into 5 unequal bins: `0`, `0.25`, `0.5`, `0.75`, `1.0`. Again, this heavy regularization of target values is to avoid overfitting as the underlying values are extremely noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c68bd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot density histogram of the target\n",
    "train[\"target\"].plot(\n",
    "  kind=\"hist\",\n",
    "  title=\"Target\",\n",
    "  figsize=(5, 3),\n",
    "  xlabel=\"Value\",\n",
    "  density=True,\n",
    "  bins=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8926",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Features\n",
    "The `features` are quantitative attributes of each stock: fundamentals like P/E ratio, technical signals like RSI, market data like short interest, secondary data like analyst ratings, and much more.\n",
    "\n",
    "The underlying definition of each feature is not important, just know that Numerai has included these features in the dataset because they believe they are predictive of the `target` either by themselves or in combination with other features.\n",
    "\n",
    "Feature values are binned into 5 equal bins: `0`, `1`, `2`, `3`, `4`. This heavy regularization of feature values is to avoid overfitting as the underlying values are extremely noisy. Unlike the target, these are integers instead of floats to reduce the storage needs of the overall dataset.\n",
    "\n",
    "If data for a particular feature is missing for that era (more common in early `eras`), then all values will be set to `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecf400",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "first_era = train[train[\"era\"] == train[\"era\"].unique()[0]]\n",
    "last_era = train[train[\"era\"] == train[\"era\"].unique()[-1]]\n",
    "last_era[feature_set[-1]].plot(\n",
    "   title=\"5 equal bins\",\n",
    "   kind=\"hist\",\n",
    "   density=True,\n",
    "   bins=50,\n",
    "   ax=ax1\n",
    ")\n",
    "first_era[feature_set[-1]].plot(\n",
    "   title=\"missing data\",\n",
    "   kind=\"hist\",\n",
    "   density=True,\n",
    "   bins=50,\n",
    "   ax=ax2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "numerai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 232.922982,
   "end_time": "2025-12-16T10:44:24.573410",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-16T10:40:31.650428",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
